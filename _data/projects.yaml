- title: SenseFi Library
  subtitle: Library and benchmark
  # group: featured
  image: https://ars.els-cdn.com/content/image/1-s2.0-S2666389923000405-gr3.jpg
  link: https://github.com/xyanchen/WiFi-CSI-Sensing-Benchmark
  description: The world-first open-source benchmark on deep learning-empowered WiFi sensing.
  tags:
    - library
    - benchmark
    - wifi-sensing

- title: MM-Fi Dataset
  subtitle: Multimodal 4D Human Dataset
  # group: featured
  image: images/gif/mm-fi-dataset.gif
  link: https://ntu-aiot-lab.github.io/mm-fi
  description: The world-first multi-modal non-intrusive 4D human dataset (RGB, Depth, LiDAR, mmWave, WiFi).
  tags:
    - dataset
    - human-sensing

- title: ARID Dataset
  subtitle: A New Dataset for Human Action Recognition in the Dark
  # group: featured
  image: images/papers/ARID-datasets.png
  link: https://xuyu0010.github.io/arid
  description: Dataset for CVPR UG2+ Challenge (2021-2022)
  tags:
    - action recognition
    - low-illumination

- title: Transfer Score
  subtitle: Benchmarking UDA
  image: images/papers/transfer-score.png
  link: https://sleepyseal.github.io/TransferScoreWeb/
  description: Unsupervised evaluation and model selection for unsupervised domain adaptation (UDA).
  repo: https://sleepyseal.github.io/TransferScoreWeb/
  tags:
    - library
    - UDA
- title: REI-Bench
  subtitle: Benchmarking Vague Human Instructions in Task Planning
  group: featured
  image: images/papers/chenxi-reibench-arxiv25.png
  link: https://arxiv.org/abs/2505.10872
  description: Model and explore how vague human instructions affect embodied task planning.
  repo: https://homeostasis-diversity.github.io/REI-Bench-web/
  tags:
    - Robot task planning
    - Vagueness
    - LLMs
- title: HoloLLM
  subtitle: Multisensory Foundation Model for Language-Grounded Human Sensing and Reasoning
  group: featured
  image: images/papers/chuhao-holollm-arxiv25.png
  link: https://arxiv.org/abs/2505.17645
  description: Multimodal Large Language Model integrating rare but powerful sensor inputs to achieve seamless human perception and reasoning.
  repo: https://github.com/ChuhaoZhou99/HoloLLM
  tags:
    - Multisensory foundation model
    - Human perception and reasoning
- title: Humanoid Teleoperation
  subtitle: Humanoid Robot Teleoperation Technique based on Meta Quest VR Headsets.
  group: featured
  image: images/papers/kuangji_xiaoyang-humanoid-arxiv25.gif
  link: #Paper Code Link#
  description: Real-time, complex humanoid teleoperation via Meta Quest VR headsets, achieving diverse manipulation tasks and whole-body locomotion.
  tags:
    - Humanoid Teleoperation
    - Manipulation
    - Whole-Body Locomotion
